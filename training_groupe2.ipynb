{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu117\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import torchvision.transforms as transforms\n",
    "import torch \n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import time\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "'''Pre-activation ResNet in PyTorch.\n",
    "\n",
    "Reference:\n",
    "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
    "    Identity Mappings in Deep Residual Networks. arXiv:1603.05027\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActBottleneck(nn.Module):\n",
    "    '''Pre-activation version of the original Bottleneck module.'''\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBottleneck, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out = self.conv3(F.relu(self.bn3(out)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        # self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        # self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        # self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        # self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        # self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
    "        # self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def PreActResNet18():\n",
    "    return PreActResNet(PreActBlock, [2,2,2,2])\n",
    "def model_1():\n",
    "    return PreActResNet(PreActBlock, [1,1,1,1])\n",
    "def test():\n",
    "    net = PreActResNet18()\n",
    "    y = net((torch.randn(512,3,32,32)))\n",
    "    print(y.size())\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Initial CIFAR10 dataset has 50000 samples\n",
      "Subset of CIFAR10 dataset has 50000 samples\n",
      "num of train batches 196\n",
      "num of test batches 40\n",
      "torch.Size([256, 3, 32, 32]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "## Normalization adapted for CIFAR10\n",
    "normalize_scratch = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "# Transforms is a list of transformations applied on the 'raw' dataset before the data is fed to the network. \n",
    "# Here, Data augmentation (RandomCrop and Horizontal Flip) are applied to each batch, differently at each epoch, on the training set data only\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "\n",
    "### The data from CIFAR10 will be downloaded in the following folder\n",
    "rootdir = './data/cifar10'\n",
    "\n",
    "c10train = CIFAR10(rootdir,train=True,download=True,transform=transform_train)\n",
    "c10test = CIFAR10(rootdir,train=False,download=True,transform=transform_test)\n",
    "## number of target samples for the final dataset\n",
    "num_train_examples = len(c10train)\n",
    "# num_samples_subset = 7500\n",
    "num_samples_subset = num_train_examples\n",
    "\n",
    "\n",
    "## We set a seed manually so as to reproduce the results easily\n",
    "seed  = 2147483647\n",
    "\n",
    "\n",
    "## Generate a list of shuffled indices ; with the fixed seed, the permutation will always be the same, for reproducibility\n",
    "indices = list(range(num_train_examples))\n",
    "np.random.RandomState(seed=seed).shuffle(indices)## modifies the list in place\n",
    "\n",
    "## We define the Subset using the generated indices \n",
    "c10train_subset = torch.utils.data.Subset(c10train,indices[:num_samples_subset])\n",
    "print(f\"Initial CIFAR10 dataset has {len(c10train)} samples\")\n",
    "print(f\"Subset of CIFAR10 dataset has {len(c10train_subset)} samples\")\n",
    "batch_size = 256\n",
    "# Finally we can define anoter dataloader for the training data\n",
    "trainloader = DataLoader(c10train,batch_size=batch_size,shuffle=True)\n",
    "testloader = DataLoader(c10test,batch_size=batch_size) \n",
    "trainloader_subset = DataLoader(c10train_subset,batch_size=batch_size,shuffle=True)\n",
    "### You can now use either trainloader (full CIFAR10) or trainloader_subset (subset of CIFAR10) to train your networks.\n",
    "print(\"num of train batches\",len(trainloader_subset))\n",
    "print(\"num of test batches\",len(testloader))\n",
    "x = next(iter(trainloader))\n",
    "print(x[0].shape, x[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, val_loader,  optimizer, scheduler, loss_fn, n_epochs=1, save_name=False, plot_losses=False):\n",
    "    start_time = time.time()\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    for e in range(n_epochs):\n",
    "        print(\"epoch\", e)\n",
    "        train_loss = 0\n",
    "        for i_batch, batch in enumerate(loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model.forward(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            if i_batch%10==0: print(\"batch\", i_batch, \"training loss\", loss.item())\n",
    "        train_loss_epoch = train_loss/(i_batch+1)\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.inference_mode():\n",
    "            val_loss = 0\n",
    "            for i_batch, batch in enumerate(val_loader):\n",
    "                model.eval()\n",
    "                images, labels = batch\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model.forward(images)\n",
    "                vloss = loss_fn(outputs, labels)\n",
    "                val_loss+= vloss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            val_loss_epoch = val_loss/(i_batch+1)\n",
    "        print(f'accuracy: {100 * correct // total} %')\n",
    "        print(\"train_loss_epoch\", train_loss_epoch)\n",
    "        print(\"val_loss_epoch\", val_loss_epoch)\n",
    "        training_losses.append(train_loss_epoch)\n",
    "        validation_losses.append(val_loss_epoch)\n",
    "        scheduler.step(val_loss_epoch)\n",
    "\n",
    "    training_time = start_time-time.time()\n",
    "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # print(pytorch_total_params)\n",
    "    if save_name:\n",
    "        torch.save({\n",
    "            'accuracy': {100 * correct // total},\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'n_epochs': n_epochs,\n",
    "            'batch_size':batch_size,\n",
    "            'loss_fn':loss_fn.__str__,\n",
    "            'total_trainable_params':pytorch_total_params,\n",
    "            'training_time': training_time,\n",
    "            }, \"./checkpoints/\"+save_name)\n",
    "        \n",
    "    if plot_losses:\n",
    "        plt.plot(range(n_epochs),validation_losses)\n",
    "        plt.plot(range(n_epochs),training_losses)\n",
    "        plt.legend(['validation loss', 'training loss'])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "PreActResNet                             [32, 10]                  --\n",
      "├─Conv2d: 1-1                            [32, 64, 32, 32]          1,728\n",
      "├─Sequential: 1-2                        [32, 32, 32, 32]          --\n",
      "│    └─PreActBlock: 2-1                  [32, 32, 32, 32]          --\n",
      "│    │    └─BatchNorm2d: 3-1             [32, 64, 32, 32]          128\n",
      "│    │    └─Sequential: 3-2              [32, 32, 32, 32]          2,048\n",
      "│    │    └─Conv2d: 3-3                  [32, 32, 32, 32]          18,432\n",
      "│    │    └─BatchNorm2d: 3-4             [32, 32, 32, 32]          64\n",
      "│    │    └─Conv2d: 3-5                  [32, 32, 32, 32]          9,216\n",
      "├─Sequential: 1-3                        [32, 64, 16, 16]          --\n",
      "│    └─PreActBlock: 2-2                  [32, 64, 16, 16]          --\n",
      "│    │    └─BatchNorm2d: 3-6             [32, 32, 32, 32]          64\n",
      "│    │    └─Sequential: 3-7              [32, 64, 16, 16]          2,048\n",
      "│    │    └─Conv2d: 3-8                  [32, 64, 16, 16]          18,432\n",
      "│    │    └─BatchNorm2d: 3-9             [32, 64, 16, 16]          128\n",
      "│    │    └─Conv2d: 3-10                 [32, 64, 16, 16]          36,864\n",
      "├─Sequential: 1-4                        [32, 128, 8, 8]           --\n",
      "│    └─PreActBlock: 2-3                  [32, 128, 8, 8]           --\n",
      "│    │    └─BatchNorm2d: 3-11            [32, 64, 16, 16]          128\n",
      "│    │    └─Sequential: 3-12             [32, 128, 8, 8]           8,192\n",
      "│    │    └─Conv2d: 3-13                 [32, 128, 8, 8]           73,728\n",
      "│    │    └─BatchNorm2d: 3-14            [32, 128, 8, 8]           256\n",
      "│    │    └─Conv2d: 3-15                 [32, 128, 8, 8]           147,456\n",
      "├─Sequential: 1-5                        [32, 256, 4, 4]           --\n",
      "│    └─PreActBlock: 2-4                  [32, 256, 4, 4]           --\n",
      "│    │    └─BatchNorm2d: 3-16            [32, 128, 8, 8]           256\n",
      "│    │    └─Sequential: 3-17             [32, 256, 4, 4]           32,768\n",
      "│    │    └─Conv2d: 3-18                 [32, 256, 4, 4]           294,912\n",
      "│    │    └─BatchNorm2d: 3-19            [32, 256, 4, 4]           512\n",
      "│    │    └─Conv2d: 3-20                 [32, 256, 4, 4]           589,824\n",
      "├─Linear: 1-6                            [32, 10]                  2,570\n",
      "==========================================================================================\n",
      "Total params: 1,239,754\n",
      "Trainable params: 1,239,754\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.44\n",
      "==========================================================================================\n",
      "Input size (MB): 0.39\n",
      "Forward/backward pass size (MB): 111.15\n",
      "Params size (MB): 4.96\n",
      "Estimated Total Size (MB): 116.50\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreActResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): PreActBlock(\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "model = model_1()\n",
    "\n",
    "batch_size = 32\n",
    "print(summary(model, input_size=(batch_size,3,32,32),verbose=0))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "batch 0 training loss 1.9743372201919556\n",
      "batch 10 training loss 2.0093066692352295\n",
      "batch 20 training loss 1.9196853637695312\n",
      "batch 30 training loss 1.7853423357009888\n",
      "batch 40 training loss 1.6906800270080566\n",
      "batch 50 training loss 1.7131340503692627\n",
      "batch 60 training loss 1.5915930271148682\n",
      "batch 70 training loss 1.639060616493225\n",
      "batch 80 training loss 1.721166729927063\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\antoi\\ensta\\annee_2\\sysemb\\training_groupe2.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m loss_fn \u001b[39m=\u001b[39m CrossEntropyLoss()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m scheduler \u001b[39m=\u001b[39m ReduceLROnPlateau(optimizer, factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-8\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     trainloader_subset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     testloader,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     optimizer,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     scheduler,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     loss_fn,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     n_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     plot_losses\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\antoi\\ensta\\annee_2\\sysemb\\training_groupe2.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/antoi/ensta/annee_2/sysemb/training_groupe2.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mif\u001b[39;00m i_batch\u001b[39m%\u001b[39m\u001b[39m10\u001b[39m\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m: \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m, i_batch, \u001b[39m\"\u001b[39m\u001b[39mtraining loss\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, factor=0.5, patience=3, min_lr=1e-8)\n",
    "train(\n",
    "    model,\n",
    "    trainloader_subset,\n",
    "    testloader,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    loss_fn,\n",
    "    n_epochs=10,\n",
    "    plot_losses=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
